{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf21346",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10248082",
   "metadata": {},
   "source": [
    "Random Forest is the most used Supervised Learning algorithm for Regression and Classification <br>\n",
    "Random Forests are made out of Decision Trees <br> <br>\n",
    "\n",
    "A random forest consists of multiple random decision trees. Two types of randomnesses are built into the trees. First, each tree is built on a random sample from the original data. Second, at each tree node, a subset of features are randomly selected to generate the best split. <br><br>\n",
    "\n",
    "Random Forests use **Ensemble Learning** method in which predictions are based on combined results of various individual models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078d94d2",
   "metadata": {},
   "source": [
    "## why Random Forest?\n",
    "\n",
    "Decision Trees are highly interpretable, but due to their simplicity, they have low bias and high variance i.e. Decision Trees tend to overfit the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ec267",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "**Bootstrapping** the data and using it's **aggregate** to make a decision is known as **Bagging**. <br>\n",
    "**Bootstrapping** --> **Random sampling with replacement** <br>\n",
    "**Aggregation**   --> **Combining results of multiple models** <br><br>\n",
    "\n",
    "In other words, Bagging is training a bunch of individual models parallely, where each model is trained on a random subset of data with resampling (each subset is of same size) and combining the output or prediction of all these (weak) models via **voting for classification** or **average for regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c96a0f",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "**Boosting** is training a bunch of individual models in a **sequential** way. Each individual model learns from mistaked made by previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9999fb9",
   "metadata": {},
   "source": [
    "**NOTE:**  Random Forest doesn't work on Boosting. It is based on Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28492170",
   "metadata": {},
   "source": [
    "## Advantages and Disadvantages of Random Forest\n",
    "\n",
    "### Advantages of Random Forest\n",
    "- It reduces overfitting in decision trees and helps to improve the accuracy\n",
    "- It is flexible to both classification and regression problems\n",
    "- It works well with both categorical and continuous values\n",
    "- It automates missing values present in the data\n",
    "Normalising of data is not required as it uses a rule-based approach\n",
    "\n",
    "\n",
    "### Disadvantages of Random Forest\n",
    "- It requires much computational power as well as resources as it builds numerous trees to combine their outputs\n",
    "- It also requires much time for training as it combines a lot of decision trees to determine the class\n",
    "- Due to the ensemble of decision trees, it also suffers interpretability and fails to determine the significance of each variable \n",
    "- It naturally makes the model biased towards features with more number of classes. This can be prevented by Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3a9861",
   "metadata": {},
   "source": [
    "### inTrees (interpretable trees)\n",
    "\n",
    "Due to ensembling, the partial dependency of each feature i.e. each feature (individually) and their correlation to target variable alongwith each feature's importance score such as Gini Impurity can be misleading to interpret (understand) the model. This is because features may react with each other and then affect the target variable. <br>\n",
    "Neither importance scores nor partial dependency plots tell how multiple features interact with the class.<br>\n",
    "\n",
    "The <b>inTrees</b> framework can be used to gain a clearer picture of what happens inside a random forest. <br><br>\n",
    "The inTrees (interpretable trees) framework extracts, measures, prunes and selects rules from a tree ensemble, and calculates frequent variable interactions. <br>\n",
    "The inTrees framework can be applied to both classification and regression problems, and is applicable to many types of tree ensembles, e.g., random forests, regularized random forests, and boosted trees.<br>\n",
    "Use inTrees packages to build Random Forest learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f872161",
   "metadata": {},
   "source": [
    "### Handling redundant features\n",
    "\n",
    "Features that are similar to each other (such as beard and facial hair), the importance scores of these features can be misleading. This may not hurt the accuracy performance but could be misleading in interpretation.<br>\n",
    "One solution would be the <b>regularized random forest (RRF)</b>.<br>\n",
    "In the tree building process, RRF memorizes the features used in previous tree nodes. While building future tree nodes, it evaluates all the features and prefers previously memorized features in splitting future treee nodes, therefore avoiding redundant features in the trees."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23ab896b",
   "metadata": {},
   "source": [
    "## Creating a Random Forest\n",
    "\n",
    "### Step 1: Create 'n' Bootstrap datasets/random subsets\n",
    "The <u>Bootstrap</u> method is a resampling technique on a population by sampling a dataset with replacement. <br><br>\n",
    "\n",
    "The Bootstrap dataset, which is same size as the original dataset is created by randomly selecting samples from the original dataset. This involves random selection with replacement. <br>\n",
    "Simply put, in each sub-dataset created, not only are data points selected (from the original dataset) at random, but they are also repeated (i.e. occurence of a data point more than once in each sample is allowed). <br><br>\n",
    "\n",
    "This process is repeated to create 'n' subsets of data\n",
    "\n",
    "### Step 2: Training 'n' Decision Trees\n",
    "Here, we make use of the fact that Decision Trees have high bias towards the data they are trained on: they produce different results based on their training data. <br>\n",
    "So, for every Bootsrapped data, we create a Decision Tree <br>\n",
    "While creating each Decision Tree, use a random subset of features at each step  (2 only/3 only/etc). <br>\n",
    "While training different Decision Trees for different subsets, use different number of features (2,3,400, etc) <br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Step 3: Use Out-of-Bag Dataset for testing\n",
    "Because of random resampling with replacement, some data points (20-30%) from the original dataset will not be used to train any Decision Tree. This data is referred to as **Out-of-Bag data** <br>\n",
    "Since this data is unseen to all the Decision Trees, we use this data to test the performance of Decision Trees and our ensamble model instead of splitting the original dataset into train-test set as we do while using other learning algorithms\n",
    "\n",
    "\n",
    "### Step 4: Aggregating the outputs of all models\n",
    "The outputs of all (weak) models are aggregated to produce a strong model. <br>\n",
    "For **Classification models, voting** is done based on prediction by each model and the class with most votes is the final prediction <br>\n",
    "For **Regression models, average** of all models is the final prediction\n",
    "\n",
    "![randomForest.png](images/randomForest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df8bb15",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e973c",
   "metadata": {},
   "source": [
    "## Random Forest using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4fde8c",
   "metadata": {},
   "source": [
    "### Random Forest Regressor using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48bde3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fb2f6248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>temp_2</th>\n",
       "      <th>temp_1</th>\n",
       "      <th>average</th>\n",
       "      <th>actual</th>\n",
       "      <th>forecast_noaa</th>\n",
       "      <th>forecast_acc</th>\n",
       "      <th>forecast_under</th>\n",
       "      <th>friend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>Wed</td>\n",
       "      <td>66</td>\n",
       "      <td>60</td>\n",
       "      <td>69.7</td>\n",
       "      <td>67</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Mon</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>45.6</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>Mon</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>67.1</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Sat</td>\n",
       "      <td>48</td>\n",
       "      <td>57</td>\n",
       "      <td>45.5</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  day week  temp_2  temp_1  average  actual  forecast_noaa  \\\n",
       "163  2016      6   15  Wed      66      60     69.7      67             65   \n",
       "328  2016     12   12  Mon      44      44     45.6      43             43   \n",
       "147  2016      5   30  Mon      64      64     67.1      71             64   \n",
       "347  2016     12   31  Sat      48      57     45.5      40             42   \n",
       "\n",
       "     forecast_acc  forecast_under  friend  \n",
       "163            73              71      69  \n",
       "328            50              45      42  \n",
       "147            70              66      69  \n",
       "347            48              47      57  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "df = pd.read_csv(\"weatherData.csv\")\n",
    "\n",
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "749d40ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (348, 12)\n"
     ]
    }
   ],
   "source": [
    "# data cleaning\n",
    "\n",
    "print('Shape :', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "06295fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 348 entries, 0 to 347\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   year            348 non-null    int64  \n",
      " 1   month           348 non-null    int64  \n",
      " 2   day             348 non-null    int64  \n",
      " 3   week            348 non-null    object \n",
      " 4   temp_2          348 non-null    int64  \n",
      " 5   temp_1          348 non-null    int64  \n",
      " 6   average         348 non-null    float64\n",
      " 7   actual          348 non-null    int64  \n",
      " 8   forecast_noaa   348 non-null    int64  \n",
      " 9   forecast_acc    348 non-null    int64  \n",
      " 10  forecast_under  348 non-null    int64  \n",
      " 11  friend          348 non-null    int64  \n",
      "dtypes: float64(1), int64(10), object(1)\n",
      "memory usage: 32.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "02d051d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>temp_2</th>\n",
       "      <th>temp_1</th>\n",
       "      <th>average</th>\n",
       "      <th>actual</th>\n",
       "      <th>forecast_noaa</th>\n",
       "      <th>forecast_acc</th>\n",
       "      <th>forecast_under</th>\n",
       "      <th>friend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>348.0</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.477011</td>\n",
       "      <td>15.514368</td>\n",
       "      <td>62.652299</td>\n",
       "      <td>62.701149</td>\n",
       "      <td>59.760632</td>\n",
       "      <td>62.543103</td>\n",
       "      <td>57.238506</td>\n",
       "      <td>62.373563</td>\n",
       "      <td>59.772989</td>\n",
       "      <td>60.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.498380</td>\n",
       "      <td>8.772982</td>\n",
       "      <td>12.165398</td>\n",
       "      <td>12.120542</td>\n",
       "      <td>10.527306</td>\n",
       "      <td>11.794146</td>\n",
       "      <td>10.605746</td>\n",
       "      <td>10.549381</td>\n",
       "      <td>10.705256</td>\n",
       "      <td>15.626179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>49.975000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>47.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>58.200000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>69.025000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>77.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         year       month         day      temp_2      temp_1     average  \\\n",
       "count   348.0  348.000000  348.000000  348.000000  348.000000  348.000000   \n",
       "mean   2016.0    6.477011   15.514368   62.652299   62.701149   59.760632   \n",
       "std       0.0    3.498380    8.772982   12.165398   12.120542   10.527306   \n",
       "min    2016.0    1.000000    1.000000   35.000000   35.000000   45.100000   \n",
       "25%    2016.0    3.000000    8.000000   54.000000   54.000000   49.975000   \n",
       "50%    2016.0    6.000000   15.000000   62.500000   62.500000   58.200000   \n",
       "75%    2016.0   10.000000   23.000000   71.000000   71.000000   69.025000   \n",
       "max    2016.0   12.000000   31.000000  117.000000  117.000000   77.400000   \n",
       "\n",
       "           actual  forecast_noaa  forecast_acc  forecast_under      friend  \n",
       "count  348.000000     348.000000    348.000000      348.000000  348.000000  \n",
       "mean    62.543103      57.238506     62.373563       59.772989   60.034483  \n",
       "std     11.794146      10.605746     10.549381       10.705256   15.626179  \n",
       "min     35.000000      41.000000     46.000000       44.000000   28.000000  \n",
       "25%     54.000000      48.000000     53.000000       50.000000   47.750000  \n",
       "50%     62.500000      56.000000     61.000000       58.000000   60.000000  \n",
       "75%     71.000000      66.000000     72.000000       69.000000   71.000000  \n",
       "max     92.000000      77.000000     82.000000       79.000000   95.000000  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "59663946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average</th>\n",
       "      <th>actual</th>\n",
       "      <th>forecast_noaa</th>\n",
       "      <th>forecast_acc</th>\n",
       "      <th>forecast_under</th>\n",
       "      <th>friend</th>\n",
       "      <th>week_Fri</th>\n",
       "      <th>week_Mon</th>\n",
       "      <th>week_Sat</th>\n",
       "      <th>week_Sun</th>\n",
       "      <th>week_Thurs</th>\n",
       "      <th>week_Tues</th>\n",
       "      <th>week_Wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.6</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.7</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.8</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.9</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average  actual  forecast_noaa  forecast_acc  forecast_under  friend  \\\n",
       "0     45.6      45             43            50              44      29   \n",
       "1     45.7      44             41            50              44      61   \n",
       "2     45.8      41             43            46              47      56   \n",
       "3     45.9      40             44            48              46      53   \n",
       "\n",
       "   week_Fri  week_Mon  week_Sat  week_Sun  week_Thurs  week_Tues  week_Wed  \n",
       "0         1         0         0         0           0          0         0  \n",
       "1         0         0         1         0           0          0         0  \n",
       "2         0         0         0         1           0          0         0  \n",
       "3         0         1         0         0           0          0         0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "\n",
    "data = pd.get_dummies(df)\n",
    "\n",
    "data.iloc[:, 5:].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d004c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(data['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "816e6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('actual', axis = 1)\n",
    "\n",
    "features = list(data.columns)\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6b972a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test-train split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6a1e4e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline error:  5.06\n"
     ]
    }
   ],
   "source": [
    "# setting a baseline for measuring model'sp performance\n",
    "\n",
    "baseline_preds = test_X[:, features.index('average')]\n",
    "\n",
    "baseline_err   = abs(baseline_preds - test_y)\n",
    "\n",
    "print('Average baseline error: ', round(np.mean(baseline_err), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "275a22d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261, 17) (261,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0d168bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
    "\n",
    "rf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cbd4138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "acd59414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 3.8731954022988506\n",
      "R2 score : 0.7638372120725536\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "print('Mean Absolute Error :', mean_absolute_error(pred, test_y))\n",
    "print('R2 score :', r2_score(pred, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d056a3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score : 0.8232529474711994\n"
     ]
    }
   ],
   "source": [
    "# build a model without train-test-split using Out of Bag Dataset\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000, random_state=42, oob_score=True)\n",
    "model.fit(data, labels)\n",
    "print('OOB score :', model.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ef1e7",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b552dbfa",
   "metadata": {},
   "source": [
    "### Random Forest Classifier using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b3414608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2684a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "683caa9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features : ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Targets  : ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print('Features :', iris.feature_names)\n",
    "print('Targets  :', iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c95f83e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "                     'sepal length':iris.data[:,0],\n",
    "                     'sepal width':iris.data[:,1],\n",
    "                     'petal length':iris.data[:,2],\n",
    "                     'petal width':iris.data[:,3],\n",
    "                     'species':iris.target  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d16039d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width  species\n",
       "39            5.1          3.4           1.5          0.2        0\n",
       "114           5.8          2.8           5.1          2.4        2\n",
       "30            4.8          3.1           1.6          0.2        0\n",
       "38            4.4          3.0           1.3          0.2        0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1c5b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since this dataset is known to be already clean, we do not need to perform any data cleanin operations or EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c0cb3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = data.drop('species', axis=1), data['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f916c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model building\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e05d5e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca69a398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy :\", metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a91a43f",
   "metadata": {},
   "source": [
    "### Finding important features in scikit-learn\n",
    "\n",
    "Random forests also offers a good feature selection indicator.<br>\n",
    "Scikit-learn provides an extra variable with the model, which shows the relative importance or contribution of each feature in the prediction.<br>\n",
    "It automatically computes the relevance score of each feature in the training phase. Then it scales the relevance down so that the sum of all scores is 1.\n",
    "\n",
    "- First, you need to create a random forests model\n",
    "- Second, use the feature importance variable to see feature importance scores\n",
    "- Third, visualize these scores using the seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a3244a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using feature_importances_ attribute of Random Forest Classifier object to get importance of each feature\n",
    "\n",
    "feature_imp = pd.Series(rfc.feature_importances_,\n",
    "                        index=iris.feature_names).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21250554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal length (cm)    0.440752\n",
       "petal width (cm)     0.414443\n",
       "sepal length (cm)    0.099597\n",
       "sepal width (cm)     0.045207\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa0599ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing feature importance\n",
    "\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41142fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "# using this knowledge, generate model using only important features\n",
    "# here, drop 'sepal width' feature\n",
    "\n",
    "X=data[['petal length', 'petal width','sepal length']]  # Removed feature \"sepal length\"\n",
    "y=data['species']                                       \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=5) # 70% training and 30% test\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf1ae4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "467f19c2",
   "metadata": {},
   "source": [
    "### Random Forest and Outliers\n",
    "\n",
    "Usually, outliers will have a negligible effect when dealing with Tree based models because the nodes are determined based on the sample proportions in each split region and not on their absolute values. That being said if that dataset is small, it still might have an impact. <br><br>\n",
    "    \n",
    "Random forest handles outliers by essentially binning them. It is also indifferent to non-linear features.<br><br>\n",
    "\n",
    "Random Forest can be used to find Outliers in a dataset by\n",
    "\n",
    "- Create a synthetic dataset of the same size as the original data. This random data set contrasts with the original data by randomly permuting each feature. The two datasets are labeled with two classes (say, “normal” and “random”) and combined\n",
    "- A random forest is built on the dataset. Random Forest classifier can be applied to test data instances\n",
    "- If the predicted class is “random”, then it is identified as an outlier\n",
    "\n",
    "![outlierDetection.png](images/outlierDetection.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3b4b812",
   "metadata": {},
   "source": [
    "### Clustering with Random Forest\n",
    "\n",
    "Similar to outlier detection, clustering with random forests saves efforts in feature preprocessing.<br><br>\n",
    "    \n",
    "The procedure is similar to outlier detection. <br>\n",
    "- Create a synthetic dataset of the same size as the original data\n",
    "- Label the original data and synthetic class with two different classes\n",
    "- Build a Random Forest Classifier on combined dataset\n",
    "- From the built random forest, a similarity score between each pair of data instances is extracted. The similarity of two data instances is measured by the percentage of trees where the two data instances appear in the same leaf node\n",
    "- With the similarity scores, clustering algorithms such as hierarchical clustering can then be used for clustering. \n",
    "![clustering.png](images/clustering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b517b27d",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
